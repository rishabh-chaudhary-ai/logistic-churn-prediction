{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:goldenrod\"><b>Customer Churn Prediction and Analysis</b></span>\n",
    "- Customer churn means losing customer interest in a business's services, products or in some cases both. This can become a challenge for any business as it impacts revenue and the market. Accurately identifying the reasons for churn can help businesses improve their marketing strategies, retention strategies and enhance customer service, ultimately improving satisfaction and profitability.\n",
    "\n",
    "- The project showcases the complete workflow of data exploration and preprocessing, feature engineering, model training with advanced classifiers, hyperparameter tuning, and model explanation using SHAP values.\n",
    "\n",
    "- The Telco customer churn dataset contains customer details related to demographics, account details, and usage patterns.\n",
    "\n",
    "- This project also emphasizes a common issue of class imbalance in churn datasets. Using oversampling techniques like SMOTE combined with weight class adjustments enhances the model's robustness. Performance is evaluated using multiple metrics and the final model is interpreted to uncover the key factors driving churn behavior.\n",
    "\n",
    "- This notebook serves as a comprehensive case study demonstrating the practical application of machine learning workflows to solve a critical business problem with real-world data and modern tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Importing the libraries</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Reading the data</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/Telco_customer_churn.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Info of the data</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Separating columns in different lists based on non-object type and object type</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cols_object = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "list_of_cols_not_object = [col for col in df.columns if df[col].dtype != \"object\"]\n",
    "print(list_of_cols_object)\n",
    "print(list_of_cols_not_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Checking for duplicated values in all columns</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].duplicated().sum() > 0:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Checking for null values in all columns</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        print(f\"Column name = {col};  total null values = {df[col].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Replacing NaN with 0</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[\"Churn Reason\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Regex to convert object type to respective data types</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pattern = re.compile(r'^[\\d\\w\\s,_\\-]+$')\n",
    "int_pattern = re.compile(r'^-?\\d+$')\n",
    "float_pattern = re.compile(r'^-?\\d*\\.\\d+$')\n",
    "datetime_pattern = re.compile(\n",
    "        r'^\\d{4}-\\d{2}-\\d{2}( \\d{2}:\\d{2}(:\\d{2}(\\.\\d{3})?)?)?$'\n",
    "    )\n",
    "\n",
    "for i in list_of_cols_object:\n",
    "    col_values = df[i].dropna().astype(str)\n",
    "    if col_values.apply(lambda x: bool(string_pattern.match(x))).all():\n",
    "        df[i] = df[i].astype(\"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    values = df[col].dropna().astype(str).sample(min(100, len(df[col])))\n",
    "    if values.apply(lambda x: bool(int_pattern.match(x))).all():\n",
    "        df[i] = pd.to_numeric(df[i], downcast='integer', errors='coerce')\n",
    "    elif values.apply(lambda x: bool(float_pattern.match(x))).all():\n",
    "        df[i] = pd.to_numeric(df[i], downcast='float', errors='coerce')\n",
    "    elif values.apply(lambda x: bool(datetime_pattern.match(x))).all():\n",
    "        df[i] = pd.to_datetime(df[i], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Payment Method\", \"Churn Reason\"]] = df[[\"Payment Method\", \"Churn Reason\"]].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Empty values replaced with 0</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(' ', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Feature Engineering</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Churn\"] = (df[\"Churn Reason\"] == \"0\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=[\"CustomerID\", \"Churn\"])\n",
    "y = df[\"Churn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:lightgreen\"><u><center>Dropping all unnecessary features from x -> dataset of independent variables/ features</center></u></span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.drop(columns=[\"Count\",\"Country\", \"State\", \"City\", \"Zip Code\", \"Latitude\", \"Longitude\", \"Churn Label\", \"Churn Value\", \"Churn Score\", \"Churn Reason\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"Total Charges\"] = x[\"Total Charges\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:lightgreen\"><u><center>Automated encoding and feature scaling using the scikit-learn linrary</center></u></span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "\n",
    "binary_cols = []\n",
    "onehot_cols = []\n",
    "numeric_cols = []\n",
    "for col in x.columns:\n",
    "    if x[col].nunique() == 2 and x[col].dtype == 'string':\n",
    "        binary_cols.append(col)\n",
    "    elif x[col].nunique() > 2 and x[col].dtype == 'string':\n",
    "        onehot_cols.append(col)\n",
    "    else:\n",
    "        numeric_cols.append(col)\n",
    "\n",
    "# label encoder for binary columns\n",
    "le = LabelEncoder()\n",
    "for col in binary_cols:\n",
    "    x[col] = le.fit_transform(x[col])\n",
    "\n",
    "# one hot encoder for non-binary string columns - onehot_cols\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "onehot = ohe.fit_transform(x[onehot_cols])\n",
    "onehot_dense = onehot.toarray()\n",
    "\n",
    "onehot_df = pd.DataFrame(onehot_dense, columns=ohe.get_feature_names_out(onehot_cols), index=x.index)\n",
    "\n",
    "x = x.drop(columns=onehot_cols)\n",
    "\n",
    "x = pd.concat([x, onehot_df], axis=1)\n",
    "\n",
    "# Scaling the numeric values of the columns in x\n",
    "scaler = StandardScaler()\n",
    "x[numeric_cols] = scaler.fit_transform(x[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Test Train dataset split</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Logistic regression classification</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Using SVC for model training</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm_model.fit(x_train, y_train)\n",
    "y_pred_svm = svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Using Decision Tree for model training</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(x_train, y_train)\n",
    "y_pred_dt = dt_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Using Random Forest for model training</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "y_pred_rf = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Using XGBoost for model training</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(x_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Hyper parameter tuning for better accuracy</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:lightgreen\"><u><center>Random Forest classifier hyper parameter tuning</center></u></span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = {\n",
    "    'n_estimators': [50,100,200,250],\n",
    "    'max_depth': [None, 10, 20, 25],\n",
    "    'min_samples_split': [2,5,10,15]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid = grid,\n",
    "    cv = 5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print('Best params: ', grid_search.best_params_)\n",
    "print('Best score: ', grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_grid = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_grid))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:lightgreen\"><u><center>XGB classifier hyper parameter tuning</center></u></span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = {\n",
    "    'n_estimators': [50, 100, 200, 250, 300],\n",
    "    'max_depth': [3, 6, 10, 15],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_grid_search = GridSearchCV(\n",
    "    estimator = xgb.XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    param_grid = xgb_grid,\n",
    "    cv = 5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_grid_search.fit(x_train, y_train)\n",
    "\n",
    "print('Best params: ', xgb_grid_search.best_params_)\n",
    "print('Best score: ', xgb_grid_search.best_score_)\n",
    "\n",
    "best_model = xgb_grid_search.best_estimator_\n",
    "y_pred_xgb_grid = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_xgb_grid))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred_xgb_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>SMOTE and Hyper parameter tuning for better accuracy</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:lightgreen\"><u><center>Random Forest classifier hyper parameter tuning with SMOTE</center></u></span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "param_grid_rfc = {\n",
    "    'n_estimators': [50,100,200,250],\n",
    "    'max_depth': [None, 10, 20, 25],\n",
    "    'min_samples_split': [2,5,10,15]\n",
    "}\n",
    "\n",
    "grid_search_rfc = GridSearchCV(estimator=rfc, param_grid = param_grid_rfc, cv=5, scoring='accuracy', n_jobs = -1)\n",
    "grid_search_rfc.fit(x_train_smote, y_train_smote)\n",
    "\n",
    "print('Best params: ', grid_search_rfc.best_params_)\n",
    "print('Best score: ', grid_search_rfc.best_score_)\n",
    "\n",
    "best_model_rfc = grid_search_rfc.best_estimator_\n",
    "y_pred_rfc_grid = best_model_rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_rfc_grid))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred_rfc_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:lightgreen\"><u><center>XGB classifier hyper parameter tuning with SMOTE</center></u></span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)\n",
    "xgbs = xgb.XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "param_grid_xgbs = {\n",
    "    'n_estimators': [50, 100, 200, 250, 300],\n",
    "    'max_depth': [3, 6, 10, 15],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search_xgbs = GridSearchCV(estimator=xgbs, param_grid = param_grid_xgbs, cv=5, scoring='accuracy', n_jobs = -1)\n",
    "grid_search_xgbs.fit(x_train_smote, y_train_smote)\n",
    "\n",
    "print('Best params: ', grid_search_xgbs.best_params_)\n",
    "print('Best score: ', grid_search_xgbs.best_score_)\n",
    "\n",
    "best_model_xgbs = grid_search_xgbs.best_estimator_\n",
    "y_pred_xgbs_grid = best_model_xgbs.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_xgbs_grid))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred_xgbs_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Adding class weight to RFC</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "rfc_balanced = RandomForestClassifier(class_weight='balanced',random_state=42)\n",
    "param_grid_rfc_balanced = {\n",
    "    'n_estimators': [50,100,200,250],\n",
    "    'max_depth': [None, 10, 20, 25],\n",
    "    'min_samples_split': [2,5,10,15]\n",
    "}\n",
    "\n",
    "grid_search_rfc_balanced = GridSearchCV(estimator=rfc, param_grid = param_grid_rfc_balanced, cv=5, scoring='accuracy', n_jobs = -1)\n",
    "grid_search_rfc_balanced.fit(x_train_smote, y_train_smote)\n",
    "\n",
    "print('Best params: ', grid_search_rfc_balanced.best_params_)\n",
    "print('Best score: ', grid_search_rfc_balanced.best_score_)\n",
    "\n",
    "best_model_rfc_balanced = grid_search_rfc_balanced.best_estimator_\n",
    "y_pred_rfc_grid_balanced = best_model_rfc_balanced.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_rfc_grid_balanced))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred_rfc_grid_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Using grid search cv to enhnace the score with tuning recall, f1-score and precision</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "rfc_cw = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "param_grid_rfc_cw = {\n",
    "    'n_estimators': [50,100,200,250],\n",
    "    'max_depth': [None, 10, 20, 25],\n",
    "    'min_samples_split': [2,5,10,15]\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'precision': make_scorer(precision_score)\n",
    "}\n",
    "\n",
    "grid_search_rfc_cw = GridSearchCV(\n",
    "    estimator=rfc_cw,\n",
    "    param_grid=param_grid_rfc_cw,\n",
    "    scoring=scoring,\n",
    "    refit='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_rfc_cw.fit(x_train_smote, y_train_smote)\n",
    "print('Best params:', grid_search_rfc_cw.best_params_)\n",
    "print('Best F1 score:', grid_search_rfc_cw.best_score_)\n",
    "\n",
    "Y_pred_rfc_cw = grid_search_rfc_cw.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, Y_pred_rfc_cw))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, Y_pred_rfc_cw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf with hyper parameter tuning, class weighting and SMOTE; accuracy = 0.8639175257731958, Best params:  {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 250}\n",
    "# rf with hyper parameter tuning and SMOTE; accuracy: 0.8639175257731958, Best params:  {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 250}\n",
    "# rf with just hyper parameter tuning, accuracy:  0.8097290626807523, Best params:  {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 200}\n",
    "# rf without anything above - accuracy: 0.7892122072391767\n",
    "# rf with smote, hyper parameter tuning, class weight and refiting f1-score; Best F1 score: 0.8634641371184564, Best params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 250}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Using LightGBM for classification on customer churn</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "classes = np.unique(y_train_smote)\n",
    "class_counts = np.bincount(y_train_smote)\n",
    "class_weights = {\n",
    "    cls: sum(class_counts) / c for cls, c in zip(classes, class_counts)\n",
    "}\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(class_weight = class_weights, random_state = 42)\n",
    "param_grid_lgbm = {\n",
    "    'num_leaves':[31,50],\n",
    "    'max_depth':[-1,10,20,30],\n",
    "    'learning_rate':[0.01, 0.1, 0.2],\n",
    "    'n_estimators':[100,200]\n",
    "}\n",
    "grid_lgbm = GridSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_grid=param_grid_lgbm,\n",
    "    scoring=make_scorer(f1_score),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_lgbm.fit(x_train_smote, y_train_smote)\n",
    "print('Best params LightGBM:', grid_lgbm.best_params_)\n",
    "print('Best F1 LightGBM:', grid_lgbm.best_score_)\n",
    "y_pred_lgmb = grid_lgbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lgmb))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred_lgmb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>Using CatBoost for classification on customer churn</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "classes = np.unique(y_train_smote)\n",
    "class_counts = np.bincount(y_train_smote)\n",
    "class_weights = [sum(class_counts) / c for c in class_counts]\n",
    "\n",
    "catboost = CatBoostClassifier(class_weights = class_weights, verbose=0, random_state=42)\n",
    "param_grid_cat = {\n",
    "    'depth':[6,10,20],\n",
    "    'learning_rate':[0.01, 0.1, 0.2],\n",
    "    'iterations': [100,200]\n",
    "}\n",
    "grid_cat = GridSearchCV(\n",
    "    estimator=catboost,\n",
    "    param_grid = param_grid_cat,\n",
    "    scoring=make_scorer(f1_score),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_cat.fit(x_train_smote, y_train_smote)\n",
    "print('Best params CatBoost:', grid_cat.best_params_)\n",
    "print('Best F1 CatBoost:', grid_cat.best_score_)\n",
    "y_pred_cat = grid_cat.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lgmb))\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred_lgmb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:coral\"><u><center>SHAP explanation for the best model so far for customer churn- LightGBM</center></u></span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:lightgreen\"><u><center>LightGBM is selected based on the best params and best score of 86%</center></u></span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(grid_lgbm.best_estimator_)\n",
    "shap_values = explainer.shap_values(x_train_smote)\n",
    "shap.summary_plot(shap_values, x_train_smote)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], x_train_smote.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
